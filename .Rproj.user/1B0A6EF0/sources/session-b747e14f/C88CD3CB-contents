# logistic regression to determine bankruptcy

install.packages("pscl")
library(dplyr)

mydataq2 <- read.csv("four_ratios.csv", header = T)
mydataq2[1:10,]
summary(mydataq2)

dim(mydataq2)

GGally:: ggpairs(mydataq2)

# split data into test/train data on 80:20 ratio
set.seed(123)
111*0.8
# create a sample taking 89/111 rows of data
split_idx = sample(nrow(mydataq2), 89)
mydataq2_train <- mydataq2[split_idx, ] 
# rest of the 22 observations in the test dataset
mydataq2_test <- mydataq2[-split_idx, ]

# ratio of 0 and 1 is similar
summary(as.factor(mydataq2$y))
summary(as.factor(mydataq2_train$y))

# fit 1st model using glm()
m1 <- glm(y ~ x1 + x2 + x3 + x4, family = binomial(logit), data = mydataq2_train)
summary(m1)

# calc G statistic
G_calc <- m1$null.deviance - m1$deviance
G_calc
# 81.8
Gdf <- m1$df.null - m1$df.residual
Gdf
# critical value is
qchisq(.95, df = Gdf)
# 9.49
1 - pchisq(G_calc, Gdf)
# 81.8 g stat > 9.49 critical value

# compute pseudo R2 measures for general linear regression models
pscl::pR2(m1)

# use anova to compare nested models w eachother
# is 1 factor better than 2 factor
# is 1 factor better than 3 factor etc.
anova(m1, test="Chisq")

# fit model 2 - without x2
m2 <- glm(y ~ x1 + x2 + x3, family = binomial(logit), data = mydataq2_train)
summary(m2)
# residual deviance has increased so it is closer to null deviance
# AIC has increased slightly
# we prefer this model as all variables apart from x3 are significant

# fit model 3 - without x3
m3 <- update(m2, ~. -x3, data = mydataq2_train)
summary(m3)
# residual deviance increased more - even closer to null
# AIC has increased more than the increase from 1-2
# all variables are significant but std errors are rlyyy big
# not good std deviations are big so we would want more / diff data

# obtain response predictions for test dataset using model 3
response_pr <- round(predict(m3,  mydataq2_test, type = "response"), 2)
# create df of response probabilities and actual values of y from test dataset
how_well <- data.frame(response_pr, mydataq2_test$y) %>%
  mutate(result = round(response_pr) == mydataq2_test$y)
how_well
# showing true for all values

# create confusion matrix to show all TRUE
confusion_matrix <- table(mydataq2_test$y, round(response_pr))
confusion_matrix


# obtain response predictions for test dataset using model 2
response_pr_2 <- round(predict(m2,  mydataq2_test, type = "response"), 2)
# create df of response probabilities and actual values of y from test dataset
how_well <- data.frame(response_pr_2, mydataq2_test$y) %>%
  mutate(result = round(response_pr_2) == mydataq2_test$y)
how_well
# showing true for all values

# create confusion matrix to show all TRUE
confusion_matrix_2 <- table(mydataq2_test$y, round(response_pr_2))
confusion_matrix_2

# !! slightly different to m3 results

# calc % accuracy for model 3
accuracy <- function(x){
  sum(diag(x) / (sum(rowSums(x)))) * 100
}
accuracy(confusion_matrix)


