ls(employee)
# UNDERSTANDING VARIABLE OF INTEREST
# see how many of each satisfaction score
employee %>%
group_by(Overall_SatisfactionScore) %>%
count()
# filtering out passive responses
employee <- employee %>%
filter(Overall_SatisfactionScore == 'Detractor' |
Overall_SatisfactionScore == 'Promoter')
# initial removing of variables
## due to nature of study, i am removing external factors which could affect
## overall satisfaction
employee <- employee %>%
select(-EmployeeID, -Education, -EducationType, -MaritalStatus)
# change data to factors
employee_factor <- employee %>%
mutate_if(is.character,as.factor)
summary(employee_factor)
glimpse(employee_factor)
# change our variable of interest into a dummy
employee$Overall_SatisfactionScore <-
ifelse(employee$Overall_SatisfactionScore == "Promoter", 1, 0)
# changing gender to dummy
employee$Gender <- ifelse(employee$Gender == "Male", 1, 0)
# one hot encode department & travel type data
employee <- cbind(employee[, -which(names(employee) == 'Department')],
model.matrix(~Department-1, employee))
employee <- cbind(employee[, -which(names(employee) == 'Traveltype_last_year')],
model.matrix(~Traveltype_last_year-1, employee))
# creating new ordered numerical variables for reviews & satisfaction scores
employee <- employee %>%
mutate(potential_review = case_when(
PotentialReview == "Low" ~ 1,
PotentialReview == "Medium" ~ 2,
PotentialReview == "High" ~ 3,
PotentialReview == "Very High" ~ 4
),
performance_review = case_when(
PerformanceReview == "Inconsistent" ~ 1,
PerformanceReview == "Met Expectations" ~ 2,
PerformanceReview == "Exceed Expectations" ~ 3
),
satisfaction_score = case_when(
SatisfactionScore == "Detractor" ~ 1,
SatisfactionScore == "Passive" ~ 2,
SatisfactionScore == "Promoter" ~ 3
),
job_role_satisfaction_score = case_when(
JobRole_SatisfactionScore == "Detractor" ~ 1,
JobRole_SatisfactionScore == "Passive" ~ 2,
JobRole_SatisfactionScore == "Promoter" ~ 3
))
# removing unnecessary variables
employee <- employee %>%
select(-PotentialReview, -PerformanceReview, -SatisfactionScore,
-JobRole_SatisfactionScore)
summary(employee)
glimpse(employee)
# check this has worked
sum(is.na(employee))
# moving overall satisfaction score to beginning of dataset
employee <- employee %>%
relocate(Overall_SatisfactionScore)
apply(employee , 2, mean)
# important to scale variables so all have variance = 1 (TRUE)
pca.out <- prcomp(employee, center = TRUE, scale. = TRUE)
names(pca.out)
# get all principal component loadings
pca.out$rotation
# get PC loadings for first 5 PCs
pca.out$rotation[,1:5]
dim(pca.out$x)
# plot loading vectors of first 2 PCs
biplot(pca.out, scale = 0)
# get PC loadings for first 5 PCs
pca.out$rotaxtion[,1:5]
names(pca.out)
# get all principal component loadings
pca.out$rotation
# get PC loadings for first 5 PCs
pca.out$rotaxtion[,1:5]
# get PC loadings for first 5 PCs
pca.out$rotaxtion[,1:4]
y = as.matrix(employee[,1])
x = as.matrix(employee[,2:23])
# important to scale variables so all have variance = 1 (TRUE)
pca.out <- prcomp(employee, center = TRUE, scale. = TRUE)
names(pca.out)
# get all principal component loadings
pca.out$rotation
# get PC loadings for first 5 PCs
pca.out$rotaxtion[,1:4]
dim(pca.out$x)
# plot loading vectors of first 2 PCs
biplot(pca.out, scale = 0)
# get PC loadings for first 5 PCs
pca.out$rotaxtion[1:4]
# get PC loadings for first 5 PCs
pca.out$rotation[,1:4]
# get PC loadings for first 5 PCs
pca.out$rotation[,1:5]
View(employee)
dim(pca.out$x)
ordered_vector <- pca.out$rotation[,1][order(pca.out$rotation[,1])]
view(ordered_vector)
ordered_vector <- pca.out$rotation[,1][-order(pca.out$rotation[,1])]
view(ordered_vector)
ordered_vector <- pca.out$rotation[,1][order(pca.out$rotation[,1])]
view(ordered_vector)
ordered_vector <- pca.out$rotation[,1][order(pca.out$rotation[,1:4])]
view(ordered_vector)
# create vector which
ordered_pc1 <- pca.out$rotation[,1][order(pca.out$rotation[,1])]
view(ordered_vector)
# create vector which
ordered_pc1 <- pca.out$rotation[,1][order(pca.out$rotation[,1])]
view(ordered_pc1)
view(rev(ordered_pc1))
dim(pca.out$x)
View(pca.out)
# plot loading vectors of first 2 PCs
biplot(pca.out, scale = 0)
# axes to face a different direction for easier interpretation
pca.out$rotation <- -pca.out$rotation
pca.out$x <- -pca.out$x
biplot(pca.out, scale=0)
# plot scree plot --
# checking the standard deviations of the PCs
pca.out$sdev
# the variance explained by each PC is the squared standard deviation
pca.var <- pca.out$sdev^2
pca.var
# and the proportion of variance explained is easily calculated like this
pve <- pca.var / sum(pca.var)
pve
# plotting PVE and cumulative PVE by component
par(mfrow = c(1, 2))
plot(pve,
xlab="Principal Component",
ylab="Proportion of Variance Explained",
ylim=c(0,1),
type='b')
plot(cumsum(pve),
xlab="Principal Component",
ylab="Cumulative Proportion of Variance Explained",
ylim=c(0,1),
type='b')
# cluster observations using complete linkage
hc.complete <- hclust(dist(employee), method="complete")
f
## USE PCA to see non-categorical variables?
# resetting grid space
dev.off()
# hierarchical clustering with average linkage
hc.average <- hclust(dist(employee), method="average")
# HC with single linkage
hc.single <- hclust(dist(employee), method="single")
# create view of the 3 plots
par(mfrow=c(1,3))
plot(hc.complete,
main="Complete Linkage",
xlab="",
sub="",
cex =.9)
plot(hc.average,
main="Average Linkage",
xlab="",
sub="",
cex =.9)
plot(hc.average,
main="Average Linkage",
xlab="",
sub="",
cex =.9)
plot(hc.average,
main="Average Linkage",
xlab="",
sub="",
cex =.9)
# obtain cluster labels for each observation associated with a
# given cut of the dendrogram
cutree(hc.complete, 2)
# given cut of the dendrogram
cutree(hc.complete, 2)
# cut complete dendogram into 4 clusters and assign the observation
cutree(hc.complete, 4)
plot(hc.complete,
main="Complete Linkage",
xlab="",
sub="",
cex =.9)
abline(h = 0.95, col = 'paleredviolet4')
abline(h = 0.95, col = 'violet')
# scale the numeric dataframe
employee_scaled <- scale(employee)
plot(hc.complete, main="Complete Linkage", xlab="", sub="", cex =.9)
# scale the numeric dataframe
employee_scaled <- scale(employee)
# hierarchical cluster observations using complete linkage
hc.complete <- hclust(dist(employee_scaled), method="complete")
plot(hc.complete, main="Complete Linkage", xlab="", sub="", cex =.9)
View(employee)
plot(hc.average, main="Average Linkage", xlab="", sub="", cex =.9)
# hierarchical clustering on observations using average linkage
hc.average <- hclust(dist(employee_scaled), method="average")
# hierarchical clustering on observations using single linkage
hc.single <- hclust(dist(employee_scaled), method="single")
## USE PCA to see non-categorical variables?
# resetting grid space
dev.off()
plot(hc.complete, main="Complete Linkage", xlab="", sub="", cex =.9)
plot(hc.average, main="Average Linkage", xlab="", sub="", cex =.9)
plot(hc.single, main="Single Linkage", xlab="", sub="", cex =.9)
# create view of the 3 plots
par(mfrow=c(1,3))
plot(hc.complete, main="Complete Linkage", xlab="", sub="", cex =.9)
plot(hc.average, main="Average Linkage", xlab="", sub="", cex =.9)
plot(hc.single, main="Single Linkage", xlab="", sub="", cex =.9)
# cut complete dendogram into 4 clusters and assign the observations
cutree(hc.complete, 4)
abline(h = 0.95, col = 'violet')
# cut dendogram into 8 clusters
y <- cutree(hc.complete, 8)
# plot cluster assignments of observations
plot(y)
# using correlation as a distance measure instead of euclidean distance
?dist
# correlation matrix using only numeric data prepared
# corr_mat <- cor(employee[, 1:14])
corr_mat <- cor(employee)
correlation_matrix <- as.matrix(cor(employee, method = "pearson"))
View(correlation_matrix)
View(corr_mat)
View(correlation_matrix)
dissimilarity_matrix <- as.matrix(1-abs(corr_mat))
par(mfrow = c(1,3))
hc.complete.corr <- hclust(as.dist(dissimilarity_matrix), method = "complete")
plot(hc.complete.corr, main = "Hierarchical Clustering with correlation - Scaled Complete")
hc.average.corr <- hclust(as.dist(dissimilarity_matrix), method = "average")
plot(hc.average.corr, main = "Hierarchical Clustering with correlation - Scaled Average")
hc.single.corr <- hclust(as.dist(dissimilarity_matrix), method = "single")
plot(hc.single.corr, main = "Hierarchical Clustering with correlation - Scaled Single")
View(dissimilarity_matrix)
# outputs of clusters
cutree(hc6, k = 5)
# outputs of clusters
cutree(hc.complete.corr, k = 5)
# cut complete dendogram into 4 clusters and assign the observations
cutree(hc.complete, 4)
cutree(hc.average.corr, k = 5)
# not using absolute value
dissimilarity_matrix_2 <- as.matrix(1-correlation_matrix)
hc9 <- hclust(as.dist(dissimilarity_matrix_2), method = "complete")
plot(hc6, main = "Hierarchical Clustering with correlation - Scaled Complete")
hc10 <- hclust(as.dist(dissimilarity_matrix_2), method = "single")
plot(hc7, main = "Hierarchical Clustering with correlation - Scaled Single")
hc11 <- hclust(as.dist(dissimilarity_matrix_2), method = "average")
plot(hc8, main = "Hierarchical Clustering with correlation - Scaled Average")
plot(hc9, main = "Hierarchical Clustering with correlation - Scaled Complete")
plot(hc10, main = "Hierarchical Clustering with correlation - Scaled Single")
plot(hc11, main = "Hierarchical Clustering with correlation - Scaled Average")
View(dissimilarity_matrix_2)
View(dissimilarity_matrix)
# outputs of clusters of similar variables
a <- cutree(hc.complete.corr, k = 5)
b <- cutree(hc.average.corr, k = 5)
c <- cutree(hc.single.corr, k = 5)
tb <- table(c(a,b,c, colnames(dissimilarity_matrix)))
view(tb)
tb <- table(c(a, colnames(dissimilarity_matrix)))
view(tb)
par(mfrow = c(1,1))
plot(hc.complete.corr, labels = colnames(dissimilarity_matrix))
abline(h = 0.95, col = 'paleredviolet4')
# load libraries
library(dplyr)
library(tidyverse)
abline(h = 0.95, col = 'violet')
abline(h = 1.05, col = 'violet')
plot(hc.complete.corr, labels = colnames(dissimilarity_matrix))
abline(h = 0.98, col = 'violet')
abline(h = 0.987, col = 'violet')
plot(hc.complete.corr, labels = colnames(dissimilarity_matrix))
abline(h = 0.987, col = 'violet')
plot(hc.complete.corr, labels = colnames(dissimilarity_matrix))
abline(h = 0.985, col = 'violet')
plot(hc.complete.corr, labels = colnames(dissimilarity_matrix))
abline(h = 0.982, col = 'violet')
# hierarchical clustering using a correlation-based dissimilarity matrix
# instead of the default Euclidean distance measure as above
?dist
# set.seed(10493638)
train_index <- sample(nrow(employee_factor), 0.7 * nrow(employee_factor))
train <- employee_factor[train_index]
test <- employee_factor[-train_index]
# load in data
employee <- read.csv("employee_dataset.csv", sep = ";")
# UNDERSTANDING VARIABLE OF INTEREST
# see how many of each satisfaction score
employee %>%
group_by(Overall_SatisfactionScore) %>%
count()
# filtering out passive responses
employee <- employee %>%
filter(Overall_SatisfactionScore == 'Detractor' |
Overall_SatisfactionScore == 'Promoter')
# initial removing of variables
## due to nature of study, i am removing external factors which could affect
## overall satisfaction
employee <- employee %>%
select(-EmployeeID, -Education, -EducationType, -MaritalStatus)
# change data to factors
employee_factor <- employee %>%
mutate_if(is.character,as.factor)
summary(employee_factor)
glimpse(employee_factor)
# change our variable of interest into a dummy
employee$Overall_SatisfactionScore <-
ifelse(employee$Overall_SatisfactionScore == "Promoter", 1, 0)
# changing gender to dummy
employee$Gender <- ifelse(employee$Gender == "Male", 1, 0)
# one hot encode department & travel type data
employee <- cbind(employee[, -which(names(employee) == 'Department')],
model.matrix(~Department-1, employee))
employee <- cbind(employee[, -which(names(employee) == 'Traveltype_last_year')],
model.matrix(~Traveltype_last_year-1, employee))
# creating new ordered numerical variables for reviews & satisfaction scores
employee <- employee %>%
mutate(potential_review = case_when(
PotentialReview == "Low" ~ 1,
PotentialReview == "Medium" ~ 2,
PotentialReview == "High" ~ 3,
PotentialReview == "Very High" ~ 4
),
performance_review = case_when(
PerformanceReview == "Inconsistent" ~ 1,
PerformanceReview == "Met Expectations" ~ 2,
PerformanceReview == "Exceed Expectations" ~ 3
),
satisfaction_score = case_when(
SatisfactionScore == "Detractor" ~ 1,
SatisfactionScore == "Passive" ~ 2,
SatisfactionScore == "Promoter" ~ 3
),
job_role_satisfaction_score = case_when(
JobRole_SatisfactionScore == "Detractor" ~ 1,
JobRole_SatisfactionScore == "Passive" ~ 2,
JobRole_SatisfactionScore == "Promoter" ~ 3
))
# removing unnecessary variables
employee <- employee %>%
select(-PotentialReview, -PerformanceReview, -SatisfactionScore,
-JobRole_SatisfactionScore)
summary(employee)
glimpse(employee)
# check this has worked
sum(is.na(employee))
# moving overall satisfaction score to beginning of dataset
employee <- employee %>%
relocate(Overall_SatisfactionScore)
# set.seed(10493638)
train_index <- sample(nrow(employee_factor), 0.7 * nrow(employee_factor))
train <- employee_factor[train_index]
test <- employee_factor[-train_index]
View(test)
view(train_index)
train <- employee_factor[train_index, ]
View(train)
test <- employee_factor[-train_index, ]
View(test)
# decision tree
tree_model2 <- tree(Overall_SatisfactionScore ~ ., data = train
# decision tree
tree_model2 <- tree(Overall_SatisfactionScore ~ ., data = train)
# decision tree
tree_model2 <- tree(Overall_SatisfactionScore ~ ., data = train)
# decision tree
tree_model1 <- tree(Overall_SatisfactionScore ~ ., data = train)
# decision tree
tree_model <- tree(Overall_SatisfactionScore ~ ., data = train)
# clearing environment and plotting space
rm(list=ls())
# load in data
employee <- read.csv("employee_dataset.csv", sep = ";")
# UNDERSTANDING VARIABLE OF INTEREST
# see how many of each satisfaction score
employee %>%
group_by(Overall_SatisfactionScore) %>%
count()
# filtering out passive responses
employee <- employee %>%
filter(Overall_SatisfactionScore == 'Detractor' |
Overall_SatisfactionScore == 'Promoter')
# initial removing of variables
## due to nature of study, i am removing external factors which could affect
## overall satisfaction
employee <- employee %>%
select(-EmployeeID, -Education, -EducationType, -MaritalStatus)
# change data to factors
employee_factor <- employee %>%
mutate_if(is.character,as.factor)
summary(employee_factor)
glimpse(employee_factor)
# change our variable of interest into a dummy
employee$Overall_SatisfactionScore <-
ifelse(employee$Overall_SatisfactionScore == "Promoter", 1, 0)
# changing gender to dummy
employee$Gender <- ifelse(employee$Gender == "Male", 1, 0)
# one hot encode department & travel type data
employee <- cbind(employee[, -which(names(employee) == 'Department')],
model.matrix(~Department-1, employee))
employee <- cbind(employee[, -which(names(employee) == 'Traveltype_last_year')],
model.matrix(~Traveltype_last_year-1, employee))
# creating new ordered numerical variables for reviews & satisfaction scores
employee <- employee %>%
mutate(potential_review = case_when(
PotentialReview == "Low" ~ 1,
PotentialReview == "Medium" ~ 2,
PotentialReview == "High" ~ 3,
PotentialReview == "Very High" ~ 4
),
performance_review = case_when(
PerformanceReview == "Inconsistent" ~ 1,
PerformanceReview == "Met Expectations" ~ 2,
PerformanceReview == "Exceed Expectations" ~ 3
),
satisfaction_score = case_when(
SatisfactionScore == "Detractor" ~ 1,
SatisfactionScore == "Passive" ~ 2,
SatisfactionScore == "Promoter" ~ 3
),
job_role_satisfaction_score = case_when(
JobRole_SatisfactionScore == "Detractor" ~ 1,
JobRole_SatisfactionScore == "Passive" ~ 2,
JobRole_SatisfactionScore == "Promoter" ~ 3
))
# removing unnecessary variables
employee <- employee %>%
select(-PotentialReview, -PerformanceReview, -SatisfactionScore,
-JobRole_SatisfactionScore)
summary(employee)
glimpse(employee)
# check this has worked
sum(is.na(employee))
# moving overall satisfaction score to beginning of dataset
employee <- employee %>%
relocate(Overall_SatisfactionScore)
# set seed for reproducibility
set.seed(10493638)
# 70% of data randomly sampled into training
train_index <- sample(nrow(employee_factor), 0.7 * nrow(employee_factor))
# creating train & test subset
train <- employee_factor[train_index, ]
test <- employee_factor[-train_index, ]
# decision tree
tree_model <- tree(Overall_SatisfactionScore ~ ., data = train)
# decision tree summary & plot
summary(tree_model)
plot(tree_model)
text(tree_model, pretty = 0)
tree_model2 <- tree(Overall_SatisfactionScore ~ ., data = employee_factor)
summary(tree_model2)
plot(tree_model2)
text(tree_model2, pretty = 0)
# random Forest
rf_model <- randomForest(Overall_SatisfactionScore ~ .,
data = train,
ntree = 500)
rf_model2 <- randomForest(Overall_Satisfaction ~ .,
data = employee_factor,
ntree = 500)
# random forest plot
importance(rf_model)
order(rf_model$importance)
importance(rf_model2)
rf_model2 <- randomForest(Overall_Satisfaction ~ .,
data = employee_factor,
ntree = 500)
rf_model2 <- randomForest(Overall_SatisfactionScore ~ .,
data = employee_factor,
ntree = 500)
importance(rf_model2)
order(rf_model2$importance)
plot(rf_model2)
plot(rf_model)
plot(rf_model2)
plot(rf_model)
# random Forest
rf_model <- randomForest(Overall_SatisfactionScore ~ .,
data = train,
ntree = 300)
rf_model2 <- randomForest(Overall_SatisfactionScore ~ .,
data = employee_factor,
ntree = 300)
# random forest plot
importance(rf_model)
order(rf_model$importance)
plot(rf_model)
plot(rf_model2)
plot(rf_model)
# gradient Boosting
gbm_model <- gbm(Overall_SatisfactionScore ~ .,
data = train,
n.trees = 500,
interaction.depth = 3)
gbm_model2 <- gbm(Overall_SatisfactionScore ~ .,
data = employee_factor,
n.trees = 500,
interaction.depth = 3)
# gradient Boosting
summary(gbm_model)
