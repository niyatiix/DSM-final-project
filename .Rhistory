# minor cleaning -- removing variables due to plots & nature of study
employee <- employee %>%
select(-`EducationTypeBio-technology`, -EducationTypeEconomics,
-`EducationTypeMarketing / Finance`, -`EducationTypePhycology / Behavior Sciences`,
-MaritalStatus, -Education)
employee_factor <- employee_factor %>%
select(-EmployeeID, -Education, -EducationType, -MaritalStatus)
# correlation matrix using newly cleaned numeric data
corr_mat <- cor(employee)
# convert matrix to long format
corr_matrix_melt <- melt(corr_mat)
?geom_tile
# plot correlation matrix
ggplot(corr_matrix_melt, aes(x=Var1, y=Var2, fill=value)) +
geom_tile() +
scale_fill_gradient2(low="turquoise4", mid="white", high="palevioletred4", midpoint=0) +
theme_minimal() +
labs(title = "Correlation Plot of Employee data", x = "", y = "") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
corr_tibble <- as_tibble(corr_mat)
View(corr_tibble)
View(corr_tibble)
# resetting grid space
dev.off()
par(mfrow = c(1, 1))
# important to scale variables so all have variance = 1 (TRUE)
pca.out <- prcomp(employee, center = TRUE, scale. = TRUE)
names(pca.out)
# get all principal component loadings
pca.out$rotation
# get PC loadings for first 5 PCs
pca.out$rotation[,1:5]
# get PC loadings for first 5 PCs
pca.out$rotation[,1:5]
# create vector which orders loadings of first and second principal component
ordered_pc1 <- pca.out$rotation[,1][order(pca.out$rotation[,1])]
view(rev(ordered_pc1))
ordered_pc2 <- pca.out$rotation[,2][order(pca.out$rotation[,2])]
view(rev(ordered_pc2))
# plot correlation matrix
ggplot(corr_matrix_melt, aes(x=Var1, y=Var2, fill=value)) +
geom_tile() +
scale_fill_gradient2(low="turquoise4", mid="white", high="palevioletred4", midpoint=0) +
theme_minimal() +
labs(title = "Correlation Plot of Employee data", x = "", y = "") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# plot loading vectors of first 2 PCs
biplot(pca.out, scale = 0)
# axes to face a different direction for easier interpretation
pca.out$rotation <- -pca.out$rotation
pca.out$x <- -pca.out$x
biplot(pca.out, scale=0)
# plot scree plot --
# checking the standard deviations of the PCs
pca.out$sdev
# the variance explained by each PC is the squared standard deviation
pca.var <- pca.out$sdev^2
pca.var
# proportion of variance explained
pve <- pca.var / sum(pca.var)
pve
# plotting PVE and cumulative PVE by component
par(mfrow = c(1, 2))
plot(pve,
xlab="Principal Component",
ylab="Proportion of Variance Explained",
ylim=c(0,1),
type='b')
plot(cumsum(pve),
xlab="Principal Component",
ylab="Cumulative Proportion of Variance Explained",
ylim=c(0,1),
type='b')
# scale the numeric dataframe
employee_scaled <- scale(employee)
# Exploration - Hierarchical Clustering  ----------------
dev.off()
# create dissimilarity matrix using correlation matrix from before
diss_mat <- as.matrix(1-abs(corr_mat))
par(mfrow = c(1,3))
View(diss_mat)
hc.complete.corr <- hclust(as.dist(diss_mat), method = "complete")
plot(hc.complete.corr, main = "Hierarchical Clustering with correlation - Scaled Complete")
hc.average.corr <- hclust(as.dist(diss_mat), method = "average")
plot(hc.average.corr, main = "Hierarchical Clustering with correlation - Scaled Average")
hc.single.corr <- hclust(as.dist(diss_mat), method = "single")
plot(hc.single.corr, main = "Hierarchical Clustering with correlation - Scaled Single")
hc.complete.corr <- hclust(as.dist(corr_mat), method = "complete")
plot(hc.complete.corr, main = "Hierarchical Clustering with correlation - Scaled Complete")
hc.average.corr <- hclust(as.dist(corr_mat), method = "average")
plot(hc.average.corr, main = "Hierarchical Clustering with correlation - Scaled Average")
hc.single.corr <- hclust(as.dist(corr_mat), method = "single")
plot(hc.single.corr, main = "Hierarchical Clustering with correlation - Scaled Single")
# outputs of clusters of similar variables (6 clusters)
cluster_complete <- cutree(hc.complete.corr, k = 6)
view(cluster_complete)
cluster_average <- cutree(hc.average.corr, k = 6)
view(cluster_average)
cluster_single <- cutree(hc.single.corr, k = 6)
view(cluster_single)
# plot threshold to identify clusters FROM XXX LINKAGE (6)
par(mfrow = c(1,1))
plot(hc.complete.corr, labels = colnames(diss_mat))
abline(h = 0.982, col = 'violet')
abline(h = 0.982, col = 'violet')
abline(h = 0.682, col = 'violet')
# plot threshold to identify clusters FROM XXX LINKAGE (6)
par(mfrow = c(1,1))
plot(hc.complete.corr, labels = colnames(diss_mat))
abline(h = 0.682, col = 'violet')
# plot threshold to identify clusters FROM XXX LINKAGE (6)
par(mfrow = c(1,1))
plot(hc.complete.corr, labels = colnames(diss_mat))
abline(h = 0.382, col = 'violet')
# plot threshold to identify clusters FROM XXX LINKAGE (6)
par(mfrow = c(1,1))
plot(hc.complete.corr, labels = colnames(diss_mat))
abline(h = 0.282, col = 'violet')
# plot threshold to identify clusters FROM XXX LINKAGE (6)
par(mfrow = c(1,1))
plot(hc.complete.corr, labels = colnames(diss_mat))
abline(h = 0.082, col = 'violet')
# plot threshold to identify clusters FROM XXX LINKAGE (6)
par(mfrow = c(1,1))
plot(hc.complete.corr, labels = colnames(diss_mat))
abline(h = 0.052, col = 'violet')
# plot threshold to identify clusters FROM XXX LINKAGE (6)
par(mfrow = c(1,1))
plot(hc.complete.corr, labels = colnames(diss_mat))
abline(h = 0.042, col = 'violet')
# plot threshold to identify clusters FROM XXX LINKAGE (6)
par(mfrow = c(1,1))
plot(hc.complete.corr, labels = colnames(diss_mat))
abline(h = 0.035, col = 'violet')
# plot threshold to identify clusters FROM XXX LINKAGE (6)
par(mfrow = c(1,1))
plot(hc.complete.corr, labels = colnames(diss_mat))
abline(h = 0.03, col = 'violet')
# plot threshold to identify clusters FROM XXX LINKAGE (6)
par(mfrow = c(1,1))
plot(hc.complete.corr, labels = colnames(diss_mat))
abline(h = 0.025, col = 'violet')
# plot threshold to identify clusters FROM XXX LINKAGE (6)
par(mfrow = c(1,1))
plot(hc.complete.corr, labels = colnames(diss_mat))
abline(h = 0.021, col = 'violet')
# plot threshold to identify clusters FROM XXX LINKAGE (6)
par(mfrow = c(1,1))
plot(hc.complete.corr, labels = colnames(diss_mat))
abline(h = 0.041, col = 'violet')
# plot threshold to identify clusters FROM XXX LINKAGE (6)
par(mfrow = c(1,1))
plot(hc.complete.corr, labels = colnames(diss_mat))
abline(h = 0.036, col = 'violet')
view(cluster_average)
cluster_single <- cutree(hc.single.corr, k = 6)
view(cluster_single)
a <- cutree(hc.complete.corr, k = 6)
a <- cutree(hc.complete.corr, k = 6)a
a
# set seed for reproducibility within resampling
set.seed(543)
# 80% of data randomly sampled into training
train_index <- sample(nrow(employee_factor), 0.8 * nrow(employee_factor))
# creating train & test subset
train <- employee_factor[train_index, ]
test <- employee_factor[-train_index, ]
# decision tree
tree_model <- tree(Overall_SatisfactionScore ~ ., data = train)
# decision tree summary & plot
summary(tree_model)
tree_model
plot(tree_model)
text(tree_model, pretty = 0)
set.seed(54321)
# 80% of data randomly sampled into training
train_index <- sample(nrow(employee_factor), 0.8 * nrow(employee_factor))
# creating train & test subset
train <- employee_factor[train_index, ]
test <- employee_factor[-train_index, ]
# decision tree
tree_model <- tree(Overall_SatisfactionScore ~ ., data = train)
tree_model2 <- tree(Overall_SatisfactionScore ~ ., data = employee_factor)
# decision tree summary & plot
summary(tree_model)
tree_model
plot(tree_model)
text(tree_model, pretty = 0)
set.seed(5432)
# 80% of data randomly sampled into training
train_index <- sample(nrow(employee_factor), 0.8 * nrow(employee_factor))
# creating train & test subset
train <- employee_factor[train_index, ]
test <- employee_factor[-train_index, ]
# decision tree
tree_model <- tree(Overall_SatisfactionScore ~ ., data = train)
tree_model2 <- tree(Overall_SatisfactionScore ~ ., data = employee_factor)
# decision tree summary & plot
summary(tree_model)
tree_model
plot(tree_model)
text(tree_model, pretty = 0)
set.seed(678)
# 80% of data randomly sampled into training
train_index <- sample(nrow(employee_factor), 0.8 * nrow(employee_factor))
# creating train & test subset
train <- employee_factor[train_index, ]
test <- employee_factor[-train_index, ]
# decision tree
tree_model <- tree(Overall_SatisfactionScore ~ ., data = train)
tree_model2 <- tree(Overall_SatisfactionScore ~ ., data = employee_factor)
# decision tree summary & plot
summary(tree_model)
tree_model
plot(tree_model)
set.seed(6789)
# 80% of data randomly sampled into training
train_index <- sample(nrow(employee_factor), 0.8 * nrow(employee_factor))
# creating train & test subset
train <- employee_factor[train_index, ]
test <- employee_factor[-train_index, ]
# decision tree
tree_model <- tree(Overall_SatisfactionScore ~ ., data = train)
tree_model2 <- tree(Overall_SatisfactionScore ~ ., data = employee_factor)
# decision tree summary & plot
summary(tree_model)
tree_model
plot(tree_model)
text(tree_model, pretty = 0)
set.seed(1011)
# 80% of data randomly sampled into training
train_index <- sample(nrow(employee_factor), 0.8 * nrow(employee_factor))
# creating train & test subset
train <- employee_factor[train_index, ]
test <- employee_factor[-train_index, ]
# decision tree
tree_model <- tree(Overall_SatisfactionScore ~ ., data = train)
tree_model2 <- tree(Overall_SatisfactionScore ~ ., data = employee_factor)
# decision tree summary & plot
summary(tree_model)
tree_model
plot(tree_model)
text(tree_model, pretty = 0)
set.seed(3001)
# 80% of data randomly sampled into training
train_index <- sample(nrow(employee_factor), 0.8 * nrow(employee_factor))
# creating train & test subset
train <- employee_factor[train_index, ]
test <- employee_factor[-train_index, ]
# decision tree
tree_model <- tree(Overall_SatisfactionScore ~ ., data = train)
tree_model2 <- tree(Overall_SatisfactionScore ~ ., data = employee_factor)
# decision tree summary & plot
summary(tree_model)
tree_model
plot(tree_model)
text(tree_model, pretty = 0)
set.seed(765)
# 80% of data randomly sampled into training
train_index <- sample(nrow(employee_factor), 0.8 * nrow(employee_factor))
# creating train & test subset
train <- employee_factor[train_index, ]
test <- employee_factor[-train_index, ]
# decision tree
tree_model <- tree(Overall_SatisfactionScore ~ ., data = train)
tree_model2 <- tree(Overall_SatisfactionScore ~ ., data = employee_factor)
# decision tree summary & plot
summary(tree_model)
tree_model
plot(tree_model)
text(tree_model, pretty = 0)
set.seed(7654)
# 80% of data randomly sampled into training
train_index <- sample(nrow(employee_factor), 0.8 * nrow(employee_factor))
# creating train & test subset
train <- employee_factor[train_index, ]
test <- employee_factor[-train_index, ]
# decision tree
tree_model <- tree(Overall_SatisfactionScore ~ ., data = train)
tree_model2 <- tree(Overall_SatisfactionScore ~ ., data = employee_factor)
# decision tree summary & plot
summary(tree_model)
tree_model
plot(tree_model)
text(tree_model, pretty = 0)
set.seed(111)
# 80% of data randomly sampled into training
train_index <- sample(nrow(employee_factor), 0.8 * nrow(employee_factor))
# creating train & test subset
train <- employee_factor[train_index, ]
test <- employee_factor[-train_index, ]
# decision tree
tree_model <- tree(Overall_SatisfactionScore ~ ., data = train)
tree_model2 <- tree(Overall_SatisfactionScore ~ ., data = employee_factor)
# decision tree summary & plot
summary(tree_model)
tree_model
plot(tree_model)
text(tree_model, pretty = 0)
set.seed(2)
# 80% of data randomly sampled into training
train_index <- sample(nrow(employee_factor), 0.8 * nrow(employee_factor))
# creating train & test subset
train <- employee_factor[train_index, ]
test <- employee_factor[-train_index, ]
# decision tree
tree_model <- tree(Overall_SatisfactionScore ~ ., data = train)
tree_model2 <- tree(Overall_SatisfactionScore ~ ., data = employee_factor)
# decision tree summary & plot
summary(tree_model)
tree_model
plot(tree_model)
text(tree_model, pretty = 0)
summary(tree_model2)
plot(tree_model2)
text(tree_model2, pretty = 0)
# let's prune the tree with the same approach as earlier
cv.employee <- cv.tree(tree_model)
set.seed(111)
# 80% of data randomly sampled into training
train_index <- sample(nrow(employee_factor), 0.8 * nrow(employee_factor))
# creating train & test subset
train <- employee_factor[train_index, ]
test <- employee_factor[-train_index, ]
# decision tree on training data
tree_model <- tree(Overall_SatisfactionScore ~ ., data = train)
summary(tree_model)
tree_model
plot(tree_model)
text(tree_model, pretty = 0)
# let's prune the tree with the same approach as earlier
cv.employee <- cv.tree(tree_model)
plot(cv.employee$size, cv.employee$dev, type='b')
# identify the size of the best fitting tree
best.employee <- cv.employee$size[cv.employee$dev==min(cv.employee$dev)]
# prune tree to optimal size (note: it may be the same as the original tree)
prune.employee <- prune.tree(tree_model, best=best.employee)
prune.employee
# plot the pruned tree
plot(prune.employee)
text(prune.employee)
set.seed(54321)
set.seed(111)
# 80% of data randomly sampled into training
train_index <- sample(nrow(employee_factor), 0.8 * nrow(employee_factor))
# creating train & test subset
train <- employee_factor[train_index, ]
test <- employee_factor[-train_index, ]
# decision tree on training data
tree_model <- tree(Overall_SatisfactionScore ~ ., data = train)
summary(tree_model)
tree_model
plot(tree_model)
text(tree_model, pretty = 0)
# set seed for reproducibility within resampling
set.seed(543)
set.seed(54321)
set.seed(111)
# 80% of data randomly sampled into training
train_index <- sample(nrow(employee_factor), 0.8 * nrow(employee_factor))
# creating train & test subset
train <- employee_factor[train_index, ]
test <- employee_factor[-train_index, ]
# decision tree on training data
tree_model <- tree(Overall_SatisfactionScore ~ ., data = train)
summary(tree_model)
tree_model
plot(tree_model)
text(tree_model, pretty = 0)
set.seed(54321)
set.seed(111)
# 80% of data randomly sampled into training
train_index <- sample(nrow(employee_factor), 0.8 * nrow(employee_factor))
# creating train & test subset
train <- employee_factor[train_index, ]
test <- employee_factor[-train_index, ]
# decision tree on training data
tree_model <- tree(Overall_SatisfactionScore ~ ., data = train)
summary(tree_model)
tree_model
plot(tree_model)
text(tree_model, pretty = 0)
# decision tree on whole dataset
tree_model2 <- tree(Overall_SatisfactionScore ~ ., data = employee_factor)
summary(tree_model2)
# set seed for reproducibility within resampling
set.seed(543)
set.seed(54321)
set.seed(111)
# 80% of data randomly sampled into training
train_index <- sample(nrow(employee_factor), 0.8 * nrow(employee_factor))
# creating train & test subset
train <- employee_factor[train_index, ]
test <- employee_factor[-train_index, ]
# decision tree on training data
tree_model <- tree(Overall_SatisfactionScore ~ ., data = train)
summary(tree_model)
tree_model
plot(tree_model)
text(tree_model, pretty = 0)
# decision tree on whole dataset
tree_model2 <- tree(Overall_SatisfactionScore ~ ., data = employee_factor)
set.seed(54)
# 80% of data randomly sampled into training
train_index <- sample(nrow(employee_factor), 0.8 * nrow(employee_factor))
# creating train & test subset
train <- employee_factor[train_index, ]
test <- employee_factor[-train_index, ]
# decision tree on training data
tree_model <- tree(Overall_SatisfactionScore ~ ., data = train)
summary(tree_model)
tree_model
plot(tree_model)
text(tree_model, pretty = 0)
set.seed(10493638)
# 80% of data randomly sampled into training
train_index <- sample(nrow(employee_factor), 0.8 * nrow(employee_factor))
# creating train & test subset
train <- employee_factor[train_index, ]
test <- employee_factor[-train_index, ]
# decision tree on training data
tree_model <- tree(Overall_SatisfactionScore ~ ., data = train)
summary(tree_model)
tree_model
plot(tree_model)
set.seed(1049)
# 80% of data randomly sampled into training
train_index <- sample(nrow(employee_factor), 0.8 * nrow(employee_factor))
# creating train & test subset
train <- employee_factor[train_index, ]
test <- employee_factor[-train_index, ]
# decision tree on training data
tree_model <- tree(Overall_SatisfactionScore ~ ., data = train)
summary(tree_model)
tree_model
plot(tree_model)
text(tree_model, pretty = 0)
set.seed(104)
# 80% of data randomly sampled into training
train_index <- sample(nrow(employee_factor), 0.8 * nrow(employee_factor))
# creating train & test subset
train <- employee_factor[train_index, ]
test <- employee_factor[-train_index, ]
# decision tree on training data
tree_model <- tree(Overall_SatisfactionScore ~ ., data = train)
summary(tree_model)
tree_model
plot(tree_model)
text(tree_model, pretty = 0)
# set seed for reproducibility within resampling
set.seed(543)
# 80% of data randomly sampled into training
train_index <- sample(nrow(employee_factor), 0.8 * nrow(employee_factor))
# creating train & test subset
train <- employee_factor[train_index, ]
test <- employee_factor[-train_index, ]
# decision tree on training data
tree_model <- tree(Overall_SatisfactionScore ~ ., data = train)
summary(tree_model)
tree_model
plot(tree_model)
text(tree_model, pretty = 0)
set.seed(54321)
set.seed(111)
set.seed(54321)
# 80% of data randomly sampled into training
train_index <- sample(nrow(employee_factor), 0.8 * nrow(employee_factor))
# creating train & test subset
train <- employee_factor[train_index, ]
test <- employee_factor[-train_index, ]
# decision tree on training data
tree_model <- tree(Overall_SatisfactionScore ~ ., data = train)
summary(tree_model)
tree_model
plot(tree_model)
text(tree_model, pretty = 0)
set.seed(111)
# 80% of data randomly sampled into training
train_index <- sample(nrow(employee_factor), 0.8 * nrow(employee_factor))
# creating train & test subset
train <- employee_factor[train_index, ]
test <- employee_factor[-train_index, ]
# decision tree on training data
tree_model <- tree(Overall_SatisfactionScore ~ ., data = train)
summary(tree_model)
tree_model
plot(tree_model)
text(tree_model, pretty = 0)
bag_employee <- bagging(Overall_SatisfactionScore ~ .,
data = train,
nbagg = 200,
coob = TRUE)
bag_employee
# visualize the importance of the predictor variables
# by calculating the total reduction in RSS
#calculate variable importance
VI <- data.frame(var=names(train[,-1]), imp=varImp(bag_employee))
#sort variable importance descending
VI_plot <- VI[order(VI$Overall, decreasing=TRUE),]
print(VI_plot)
#visualize variable importance with horizontal bar plot
barplot(VI_plot$Overall,
names.arg=rownames(VI_plot),
horiz=TRUE,
col='palevioletred4',
xlab='Variable Importance')
View(VI_plot)
View(tree_model)
text(tree_model, pretty = 0)
tree_model
plot(tree_model)
text(tree_model, pretty = 0)
